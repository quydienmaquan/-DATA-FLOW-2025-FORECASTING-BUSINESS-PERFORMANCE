{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 172ms/step - loss: 0.0049 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - loss: 0.0042 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - loss: 0.0042 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - loss: 0.0048 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 136ms/step - loss: 0.0041 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - loss: 0.0038 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - loss: 0.0038 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 151ms/step - loss: 0.0040 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - loss: 0.0033 - val_loss: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 151ms/step - loss: 0.0040 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 160ms/step - loss: 0.0037 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 156ms/step - loss: 0.0032 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - loss: 0.0034 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - loss: 0.0037 - val_loss: 0.0013 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - loss: 0.0032 - val_loss: 0.0013 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - loss: 0.0031 - val_loss: 0.0013 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 212ms/step - loss: 0.0030 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 322ms/step - loss: 0.0028 - val_loss: 0.0015 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.0034 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - loss: 0.0034 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - loss: 0.0031 - val_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 326ms/step - loss: 0.0029 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 282ms/step - loss: 0.0037 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 240ms/step - loss: 0.0027 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - loss: 0.0027 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 246ms/step - loss: 0.0031 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 244ms/step - loss: 0.0036 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 228ms/step - loss: 0.0030 - val_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 229ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 225ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 223ms/step - loss: 0.0021 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 288ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 292ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 298ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 267ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 304ms/step - loss: 0.0024 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 275ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 260ms/step - loss: 0.0024 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 263ms/step - loss: 0.0022 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 288ms/step - loss: 0.0021 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 244ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 218ms/step - loss: 0.0021 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 194ms/step - loss: 0.0026 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 135ms/step - loss: 0.0024 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - loss: 0.0028 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 165ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.5625e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 175ms/step - loss: 0.0025 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.0023 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.5625e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - loss: 0.0026 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 180ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 0.0020 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 0.0020 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 0.0022 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 0.0020 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 134ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 0.0020 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 0.0023 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0020 - val_loss: 9.9999e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 0.0023 - val_loss: 9.9675e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - loss: 0.0024 - val_loss: 0.0010 - learning_rate: 1.0000e-05\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (505,4) (3,) (505,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Chuyển đổi dữ liệu về dạng gốc\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m y_test_inv \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mpad(y_test, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m))[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     76\u001b[0m y_pred_inv \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mpad(y_pred, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m))[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Vẽ biểu đồ\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:572\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    563\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    565\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    566\u001b[0m     X,\n\u001b[0;32m    567\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[0;32m    568\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_array_api\u001b[38;5;241m.\u001b[39msupported_float_dtypes(xp),\n\u001b[0;32m    569\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    570\u001b[0m )\n\u001b[1;32m--> 572\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    573\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (505,4) (3,) (505,4) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "train_file = \"D:/Du An/Data FLow/v1/data/train.csv\"\n",
    "test_file = \"D:/Du An/Data FLow/v1/data/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# Chuyển đổi cột Date thành kiểu datetime\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "\n",
    "# Thêm thông tin ngày trong tuần\n",
    "df_train['DayOfWeek'] = df_train['Date'].dt.dayofweek\n",
    "df_test['DayOfWeek'] = df_test['Date'].dt.dayofweek\n",
    "\n",
    "# Sắp xếp theo thời gian\n",
    "df_train.sort_values(by='Date', inplace=True)\n",
    "df_test.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Chọn dữ liệu doanh thu và số lượng bán theo ngày\n",
    "sales_train = df_train[['Date', 'Revenue', 'Units', 'DayOfWeek']].groupby('Date').sum()\n",
    "sales_test = df_test[['Date', 'Revenue', 'Units', 'DayOfWeek']].groupby('Date').sum()\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "sales_train_scaled = scaler.fit_transform(sales_train)\n",
    "sales_test_scaled = scaler.transform(sales_test)\n",
    "\n",
    "# Tạo tập dữ liệu cho LSTM\n",
    "def create_lstm_dataset(data, time_step=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step):\n",
    "        X.append(data[i:(i + time_step), :])\n",
    "        y.append(data[i + time_step, :])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 30\n",
    "X_train, y_train = create_lstm_dataset(sales_train_scaled, time_step)\n",
    "X_test, y_test = create_lstm_dataset(sales_test_scaled, time_step)\n",
    "\n",
    "# Xây dựng mô hình Bi-Directional LSTM\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, return_sequences=True, input_shape=(time_step, X_train.shape[2]))),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32, return_sequences=False)),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Thêm EarlyStopping và ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Dự báo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Chuyển đổi dữ liệu về dạng gốc\n",
    "y_test_inv = scaler.inverse_transform(np.pad(y_test, ((0, 0), (0, 1)), mode='constant'))[:, :-1]\n",
    "y_pred_inv = scaler.inverse_transform(np.pad(y_pred, ((0, 0), (0, 1)), mode='constant'))[:, :-1]\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "dates = sales_test.index[time_step:]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, y_test_inv[:, 0], label='Thực tế (Revenue)')\n",
    "plt.plot(dates, y_pred_inv[:, 0], label='Dự báo (Revenue)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo các đặc trưng thời gian\n",
    "def create_features(df):\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "df_train = create_features(df_train)\n",
    "df_test = create_features(df_test)\n",
    "\n",
    "# Chọn đặc trưng và target\n",
    "features = ['Year', 'Month', 'Day', 'DayOfWeek', 'Units']\n",
    "target = 'Revenue'\n",
    "\n",
    "# Chuẩn hóa dữ liệu đầu vào\n",
    "scaler = MinMaxScaler()\n",
    "df_train[features] = scaler.fit_transform(df_train[features])\n",
    "df_test[features] = scaler.transform(df_test[features])\n",
    "\n",
    "# Chia tập dữ liệu\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[features], df_train[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Huấn luyện\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự báo\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "mae = mean_absolute_error(y_val, y_pred_rf)\n",
    "mse = mean_squared_error(y_val, y_pred_rf)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred_rf)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp dữ liệu theo thời gian\n",
    "df_train.sort_values(by='Date', inplace=True)\n",
    "df_test.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Tạo đặc trưng thời gian\n",
    "def create_features(df):\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "df_train = create_features(df_train)\n",
    "df_test = create_features(df_test)\n",
    "\n",
    "# Tạo lag features (lấy giá trị doanh thu của ngày trước đó làm input)\n",
    "def create_lag_features(df, lag_days=[1, 7, 14]):\n",
    "    for lag in lag_days:\n",
    "        df[f'Revenue_Lag{lag}'] = df['Revenue'].shift(lag)\n",
    "    return df\n",
    "\n",
    "df_train = create_lag_features(df_train)\n",
    "df_test = create_lag_features(df_test)\n",
    "\n",
    "# Loại bỏ các hàng có giá trị NaN do shift()\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Chọn các cột đầu vào và đầu ra\n",
    "features = ['Year', 'Month', 'Day', 'DayOfWeek', 'Units', 'Revenue_Lag1', 'Revenue_Lag7', 'Revenue_Lag14']\n",
    "target = 'Revenue'\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = MinMaxScaler()\n",
    "df_train[features] = scaler.fit_transform(df_train[features])\n",
    "df_test[features] = scaler.transform(df_test[features])\n",
    "\n",
    "# Chia tập dữ liệu train và validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[features], df_train[target], test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Khởi tạo mô hình XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                             n_estimators=200, \n",
    "                             learning_rate=0.05, \n",
    "                             max_depth=6, \n",
    "                             subsample=0.8, \n",
    "                             colsample_bytree=0.8, \n",
    "                             random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# Dự báo\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "mae = mean_absolute_error(y_val, y_pred_xgb)\n",
    "mse = mean_squared_error(y_val, y_pred_xgb)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred_xgb)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo đặc trưng thời gian\n",
    "def create_features(df):\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "df_train = create_features(df_train)\n",
    "df_test = create_features(df_test)\n",
    "\n",
    "# Tạo lag features (giá trị doanh thu của ngày trước đó làm input)\n",
    "def create_lag_features(df, lag_days=[1, 7, 14]):\n",
    "    for lag in lag_days:\n",
    "        df[f'Revenue_Lag{lag}'] = df['Revenue'].shift(lag)\n",
    "    return df\n",
    "\n",
    "df_train = create_lag_features(df_train)\n",
    "df_test = create_lag_features(df_test)\n",
    "\n",
    "# Loại bỏ các hàng NaN do shift()\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Chọn các cột đặc trưng và nhãn\n",
    "features = ['Year', 'Month', 'Day', 'DayOfWeek', 'Units', 'Revenue_Lag1', 'Revenue_Lag7', 'Revenue_Lag14']\n",
    "target = 'Revenue'\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = MinMaxScaler()\n",
    "df_train[features] = scaler.fit_transform(df_train[features])\n",
    "df_test[features] = scaler.transform(df_test[features])\n",
    "\n",
    "# Chia dữ liệu thành tập train và validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[features], df_train[target], test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Khởi tạo mô hình LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt', \n",
    "    objective='regression', \n",
    "    n_estimators=500, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=6, \n",
    "    num_leaves=31,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='rmse', early_stopping_rounds=20, verbose=10)\n",
    "\n",
    "# Dự báo\n",
    "y_pred_lgb = lgb_model.predict(X_val)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "mae = mean_absolute_error(y_val, y_pred_lgb)\n",
    "mse = mean_squared_error(y_val, y_pred_lgb)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred_lgb)\n",
    "\n",
    "print(f\"📌 MAE: {mae}\")\n",
    "print(f\"📌 RMSE: {rmse}\")\n",
    "print(f\"📌 R-squared: {r2}\")\n",
    "\n",
    "# Trực quan hóa kết quả\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dates = df_train['Date'].iloc[-len(y_val):]  # Lấy ngày tương ứng với tập validation\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, y_val.values, label='Thực tế (Revenue)', color='blue')\n",
    "plt.plot(dates, y_pred_lgb, label='Dự báo (Revenue)', color='red')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
